{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cifar100.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMogbxsR4lG9GGin8W89dNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arahman1993/CIFAR-100-Bagging_CNN/blob/main/Copy_of_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxB13TYjYeQ7",
        "outputId": "905ec19a-33ed-4be7-aa3b-1fb06fea82ee"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtGOrveBYsH_",
        "outputId": "1c5098ef-af9a-4740-ba03-591b0d82a709"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "# Download dataset of CIFAR-100 (Canadian Institute for Advanced Research)\n",
        "(x_train,y_train),(x_test,y_test) = cifar100.load_data()\n",
        " \n",
        "# Check the shape of the array \n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        " \n",
        "# Number of data set samples \n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        " \n",
        "# Data format confirmation \n",
        "print(type(x_test))\n",
        "print(type(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "y_test shape: (10000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_hqDMuSaGJH"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPool2D\n",
        "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
        "from keras.utils import np_utils\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        " \n",
        "# Normalize the image in a range of 0-1\n",
        "x_train = x_train.astype('float32')/255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        " \n",
        "# Convert correct answer labels of y_train,y_test to One-Hot\n",
        "y_train = np_utils.to_categorical(y_train,100)\n",
        "#y_test = np_utils.to_categorical(y_test,100)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QL2eriVBYel"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vQ3uOkvBn-x"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model1(trainX, trainy):\n",
        "    model = Sequential()\n",
        " \n",
        "    model.add(Conv2D(32,(3,3),padding='VALID',input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Conv2D(64,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    # fit model\n",
        "    history1 = model.fit(trainX,trainy,batch_size=128,epochs=50,verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIq5Gguhymyk"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model2(trainX, trainy):\n",
        "    model = Sequential()\n",
        " \n",
        "    model.add(Conv2D(16,(3,3),padding='VALID',input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(16,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Conv2D(32,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    # fit model\n",
        "    history2 = model.fit(trainX,trainy,batch_size=128,epochs=50,verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZygVrxynrz"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model3(trainX, trainy):\n",
        "    model = Sequential()\n",
        " \n",
        "    model.add(Conv2D(8,(3,3),padding='VALID',input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(8,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Conv2D(16,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(16,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    # fit model\n",
        "    history3 = model.fit(trainX,trainy,batch_size=128,epochs=50,verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke7e-GUBAX0d"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model4(trainX, trainy):\n",
        "    model = Sequential()\n",
        " \n",
        "    model.add(Conv2D(32,(3,3),padding='VALID',input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    # fit model\n",
        "    history4 = model.fit(trainX,trainy,batch_size=128,epochs=50,verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XE1t-IlAxTx"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model5(trainX, trainy):\n",
        "    model = Sequential()\n",
        " \n",
        "    model.add(Conv2D(16,(3,3),padding='VALID',input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(16,(3,3),padding='VALID'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        " \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    # fit model\n",
        "    history5 = model.fit(trainX,trainy,batch_size=128,epochs=50,verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7NCHEuOCSm7"
      },
      "source": [
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "    # make predictions\n",
        "    yhats = [model.predict(testX) for model in members]\n",
        "    yhats = array(yhats)\n",
        "    # sum across ensemble members\n",
        "    summed = numpy.sum(yhats, axis=0)\n",
        "    # argmax across classes\n",
        "    result = argmax(summed, axis=1)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjcoRQFLCdTp"
      },
      "source": [
        "# evaluate ensemble model\n",
        "def evaluate_members(members, testX, testy):\n",
        "    # make prediction\n",
        "    yhat = ensemble_predictions(members, testX)\n",
        "    # calculate accuracy\n",
        "    return accuracy_score(testy, yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziykHJQQCo9T",
        "outputId": "67abaf6a-f664-4b67-c5c7-7271d8ac9d62"
      },
      "source": [
        "# repeated evaluation\n",
        "bag = [\"fit_model1\", \"fit_model2\", \"fit_model3\", \"fit_model4\",\"fit_model5\"]\n",
        "scores = list()\n",
        "import time\n",
        "start_time = time.time()\n",
        "# fit all models\n",
        "for i in bag:\n",
        "   members = [eval(i + \"(x_train, y_train)\")]\n",
        "   # evaluate ensemble\n",
        "   score = evaluate_members(members, x_test, y_test)\n",
        "   print('> %.3f' % score)\n",
        "   scores.append(score)\n",
        "# summarize the distribution of scores\n",
        "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 936,580\n",
            "Trainable params: 936,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.1073 - accuracy: 0.0687\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.5455 - accuracy: 0.1581\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.2539 - accuracy: 0.2115\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.0549 - accuracy: 0.2484\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.8953 - accuracy: 0.2778\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.7693 - accuracy: 0.3041\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.6647 - accuracy: 0.3261\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5760 - accuracy: 0.3408\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4998 - accuracy: 0.3554\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4291 - accuracy: 0.3717\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3816 - accuracy: 0.3788\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3099 - accuracy: 0.3969\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2675 - accuracy: 0.4045\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2164 - accuracy: 0.4137\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1762 - accuracy: 0.4220\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1401 - accuracy: 0.4309\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1182 - accuracy: 0.4356\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0714 - accuracy: 0.4445\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0450 - accuracy: 0.4499\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0170 - accuracy: 0.4560\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9976 - accuracy: 0.4588\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9634 - accuracy: 0.4661\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9458 - accuracy: 0.4710\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9206 - accuracy: 0.4757\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9038 - accuracy: 0.4795\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8806 - accuracy: 0.4829\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8571 - accuracy: 0.4904\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8403 - accuracy: 0.4929\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8148 - accuracy: 0.4976\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8094 - accuracy: 0.4982\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7854 - accuracy: 0.5059\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7798 - accuracy: 0.5072\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7502 - accuracy: 0.5121\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7442 - accuracy: 0.5132\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7319 - accuracy: 0.5176\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7166 - accuracy: 0.5211\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7001 - accuracy: 0.5240\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6907 - accuracy: 0.5228\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6794 - accuracy: 0.5259\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6663 - accuracy: 0.5300\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6560 - accuracy: 0.5334\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6407 - accuracy: 0.5373\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6373 - accuracy: 0.5356\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6137 - accuracy: 0.5376\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6137 - accuracy: 0.5431\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5988 - accuracy: 0.5467\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5940 - accuracy: 0.5480\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.5942 - accuracy: 0.5467\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5826 - accuracy: 0.5480\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.5753 - accuracy: 0.5518\n",
            "> 0.477\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 16)        448       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 30, 30, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               205056    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               25700     \n",
            "=================================================================\n",
            "Total params: 247,412\n",
            "Trainable params: 247,412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 4.2901 - accuracy: 0.0487\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.7338 - accuracy: 0.1250\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.5056 - accuracy: 0.1666\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3613 - accuracy: 0.1908\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.2523 - accuracy: 0.2105\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.1684 - accuracy: 0.2269\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0936 - accuracy: 0.2397\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0536 - accuracy: 0.2480\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0018 - accuracy: 0.2572\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.9460 - accuracy: 0.2693\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.9084 - accuracy: 0.2724\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.8697 - accuracy: 0.2821\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.8404 - accuracy: 0.2882\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.8023 - accuracy: 0.2940\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7792 - accuracy: 0.2977\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7487 - accuracy: 0.3044\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7190 - accuracy: 0.3093\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7022 - accuracy: 0.3147\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6784 - accuracy: 0.3208\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6539 - accuracy: 0.3250\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6390 - accuracy: 0.3289\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6327 - accuracy: 0.3306\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6052 - accuracy: 0.3335\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5905 - accuracy: 0.3363\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5782 - accuracy: 0.3388\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5556 - accuracy: 0.3414\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5444 - accuracy: 0.3429\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5333 - accuracy: 0.3467\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5210 - accuracy: 0.3489\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5114 - accuracy: 0.3503\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4952 - accuracy: 0.3526\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4966 - accuracy: 0.3530\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4769 - accuracy: 0.3587\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4629 - accuracy: 0.3598\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.4479 - accuracy: 0.3625\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4483 - accuracy: 0.3627\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4421 - accuracy: 0.3632\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4351 - accuracy: 0.3649\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4225 - accuracy: 0.3675\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4155 - accuracy: 0.3688\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.4147 - accuracy: 0.3681\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3972 - accuracy: 0.3744\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3906 - accuracy: 0.3742\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.3848 - accuracy: 0.3746\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3747 - accuracy: 0.3764\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3733 - accuracy: 0.3784\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3711 - accuracy: 0.3786\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3671 - accuracy: 0.3778\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3639 - accuracy: 0.3797\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3533 - accuracy: 0.3804\n",
            "> 0.415\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 30, 30, 8)         224       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 30, 30, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 8)         584       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 68,524\n",
            "Trainable params: 68,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 4.4411 - accuracy: 0.0245\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 4.1063 - accuracy: 0.0673\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.8714 - accuracy: 0.1013\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.7198 - accuracy: 0.1272\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.6198 - accuracy: 0.1417\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.5506 - accuracy: 0.1562\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.5032 - accuracy: 0.1632\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.4669 - accuracy: 0.1708\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.4286 - accuracy: 0.1753\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3929 - accuracy: 0.1837\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3600 - accuracy: 0.1873\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3489 - accuracy: 0.1915\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.3260 - accuracy: 0.1944\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3072 - accuracy: 0.1976\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.2915 - accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2701 - accuracy: 0.2040\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2524 - accuracy: 0.2082\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2415 - accuracy: 0.2096\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2364 - accuracy: 0.2125\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2109 - accuracy: 0.2158\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.2165 - accuracy: 0.2142\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.2067 - accuracy: 0.2159\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1832 - accuracy: 0.2194\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1766 - accuracy: 0.2230\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1634 - accuracy: 0.2246\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1538 - accuracy: 0.2252\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1474 - accuracy: 0.2253\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1383 - accuracy: 0.2279\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1254 - accuracy: 0.2304\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.1200 - accuracy: 0.2302\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.1160 - accuracy: 0.2325\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.1110 - accuracy: 0.2360\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.1028 - accuracy: 0.2353\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0841 - accuracy: 0.2384\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0813 - accuracy: 0.2402\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0844 - accuracy: 0.2370\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0691 - accuracy: 0.2401\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0660 - accuracy: 0.2403\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0571 - accuracy: 0.2411\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0650 - accuracy: 0.2410\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0561 - accuracy: 0.2433\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0462 - accuracy: 0.2434\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0390 - accuracy: 0.2466\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0346 - accuracy: 0.2466\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0313 - accuracy: 0.2447\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0273 - accuracy: 0.2479\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0229 - accuracy: 0.2495\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0200 - accuracy: 0.2480\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.0154 - accuracy: 0.2470\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0103 - accuracy: 0.2480\n",
            "> 0.318\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 3,273,220\n",
            "Trainable params: 3,273,220\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.9219 - accuracy: 0.1072\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.2278 - accuracy: 0.2230\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.8988 - accuracy: 0.2833\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6691 - accuracy: 0.3283\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4972 - accuracy: 0.3619\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3434 - accuracy: 0.3896\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2207 - accuracy: 0.4165\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1092 - accuracy: 0.4399\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9942 - accuracy: 0.4637\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8981 - accuracy: 0.4843\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8144 - accuracy: 0.5024\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.7336 - accuracy: 0.5186\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.6517 - accuracy: 0.5389\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5748 - accuracy: 0.5598\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5127 - accuracy: 0.5703\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4457 - accuracy: 0.5871\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3878 - accuracy: 0.5992\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3370 - accuracy: 0.6087\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2747 - accuracy: 0.6268\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2355 - accuracy: 0.6366\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1920 - accuracy: 0.6501\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1576 - accuracy: 0.6555\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1224 - accuracy: 0.6657\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0805 - accuracy: 0.6778\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0466 - accuracy: 0.6838\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0093 - accuracy: 0.6966\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9827 - accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9658 - accuracy: 0.7084\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9337 - accuracy: 0.7155\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9110 - accuracy: 0.7213\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8844 - accuracy: 0.7302\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8621 - accuracy: 0.7372\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8548 - accuracy: 0.7386\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8160 - accuracy: 0.7474\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8063 - accuracy: 0.7495\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7851 - accuracy: 0.7565\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7759 - accuracy: 0.7601\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7565 - accuracy: 0.7670\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7472 - accuracy: 0.7686\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7227 - accuracy: 0.7764\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7229 - accuracy: 0.7722\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7118 - accuracy: 0.7783\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6907 - accuracy: 0.7846\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6890 - accuracy: 0.7852\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6595 - accuracy: 0.7934\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6701 - accuracy: 0.7917\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6524 - accuracy: 0.7967\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6436 - accuracy: 0.7974\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6374 - accuracy: 0.8022\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6247 - accuracy: 0.8046\n",
            "> 0.389\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 30, 30, 16)        448       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 30, 30, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               25700     \n",
            "=================================================================\n",
            "Total params: 831,540\n",
            "Trainable params: 831,540\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 4.1477 - accuracy: 0.0695\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.5881 - accuracy: 0.1533\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3324 - accuracy: 0.1997\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.1517 - accuracy: 0.2323\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.0281 - accuracy: 0.2532\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.9333 - accuracy: 0.2738\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.8568 - accuracy: 0.2842\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7898 - accuracy: 0.2977\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.7452 - accuracy: 0.3074\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6968 - accuracy: 0.3144\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6526 - accuracy: 0.3214\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.6123 - accuracy: 0.3293\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5846 - accuracy: 0.3377\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5503 - accuracy: 0.3422\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.5232 - accuracy: 0.3441\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4894 - accuracy: 0.3513\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4497 - accuracy: 0.3634\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4243 - accuracy: 0.3658\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4036 - accuracy: 0.3684\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3813 - accuracy: 0.3729\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3563 - accuracy: 0.3768\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3275 - accuracy: 0.3826\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.3075 - accuracy: 0.3913\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2837 - accuracy: 0.3904\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2486 - accuracy: 0.3997\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2420 - accuracy: 0.4014\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2058 - accuracy: 0.4059\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1973 - accuracy: 0.4075\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1834 - accuracy: 0.4114\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1682 - accuracy: 0.4139\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1395 - accuracy: 0.4206\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1263 - accuracy: 0.4219\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1107 - accuracy: 0.4253\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0940 - accuracy: 0.4300\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0668 - accuracy: 0.4388\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0614 - accuracy: 0.4368\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0505 - accuracy: 0.4408\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0328 - accuracy: 0.4415\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0196 - accuracy: 0.4431\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0133 - accuracy: 0.4455\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9875 - accuracy: 0.4523\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9760 - accuracy: 0.4567\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9773 - accuracy: 0.4525\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9510 - accuracy: 0.4606\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9429 - accuracy: 0.4634\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9267 - accuracy: 0.4642\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9191 - accuracy: 0.4653\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9000 - accuracy: 0.4688\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8965 - accuracy: 0.4700\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8937 - accuracy: 0.4714\n",
            "> 0.374\n",
            "Scores Mean: 0.395, Standard Deviation: 0.052\n",
            "--- 618.7247977256775 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
